{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import rotate , resize\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/parth/ml/handson-ml/datasets/inception/inception_v3.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 1, 'dandelion': 0, 'roses': 2, 'sunflowers': 4, 'tulips': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "names = os.listdir(\"/home/parth/ml/Tensorflow_learning/Hands on Ml/flower_photos\")\n",
    "names.remove(names[2])\n",
    "class_to_value = { name : value for value , name in enumerate(names)}\n",
    "class_to_value         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data_ = dict()\n",
    "    for name in names :\n",
    "        path = \"/home/parth/ml/Tensorflow_learning/Hands on Ml/flower_photos\" + \"/\" + name \n",
    "        filenames = os.listdir(path)\n",
    "        temp_list = list()\n",
    "        for file in filenames :\n",
    "            file = path + \"/\" + file\n",
    "            temp_list.append(plt.imread(file , format=\"jpg\"))\n",
    "        data_[name] = temp_list\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    data_ = read_data()\n",
    "    X = list()\n",
    "    Y = list()\n",
    "    for label in data_.keys():\n",
    "        print(\"Doing Label : {}\".format(label))\n",
    "        x = data_[label]\n",
    "        for eachx in x:\n",
    "            eachx.astype(np.uint16 , copy=False)\n",
    "            eachx = resize(eachx , [299 , 299 , 3])\n",
    "            X.append(eachx)\n",
    "            Y.append(class_to_value[label])\n",
    "            print(a)\n",
    "    return X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain , ytrain = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.array(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.slim.nets import inception\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 299, 299, 3], name=\"X\")\n",
    "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "    logits, end_points = inception.inception_v3(\n",
    "        X, num_classes=1001, is_training=False)\n",
    "predictions = end_points[\"Predictions\"]\n",
    "file_writer = tf.summary.FileWriter(logdir=\"/tmp/\")\n",
    "saver = tf.train.import_meta_graph(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "CLASS_NAME_REGEX = re.compile(r\"^n\\d+\\s+(.*)\\s*$\", re.M | re.U)\n",
    "\n",
    "def load_class_names():\n",
    "    path = os.path.join(\"/home/parth/ml/handson-ml/datasets\", \"inception\", \"imagenet_class_names.txt\")\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        return CLASS_NAME_REGEX.findall(content)\n",
    "    \n",
    "class_names = [\"background\"] + load_class_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess , path)\n",
    "    file_writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.get_default_graph().get_operation_by_name(\"InceptionV3/InceptionV3/Mixed_7b/concat\")\n",
    "Layer = outputs.outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.stop_gradient(Layer)\n",
    "layer = tf.layers.conv2d(layer , activation=tf.nn.relu , kernel_size=1 , filters=1024  , strides=1 , padding=\"SAME\")\n",
    "layer = tf.layers.conv2d(layer , activation=tf.nn.relu , kernel_size=3 , filters=1024 , strides=2 , padding=\"SAME\")\n",
    "layer = tf.nn.local_response_normalization(layer , depth_radius=2)\n",
    "layer = tf.layers.conv2d(layer , activation=tf.nn.relu , kernel_size=1 , filters=256  , strides=1 , padding=\"SAME\")\n",
    "layer = tf.layers.conv2d(layer , activation=tf.nn.relu , kernel_size=3 , filters=512  , strides=1,  padding=\"SAME\")\n",
    "layer = tf.layers.average_pooling2d(layer , pool_size=2 , strides=2 , padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = tf.layers.flatten(layer)\n",
    "dense = tf.layers.dense(flatten , units=100 , \n",
    "                        activation=tf.nn.elu , kernel_initializer=tf.variance_scaling_initializer())\n",
    "logits_new = tf.layers.dense(dense , units=5  , kernel_initializer=tf.variance_scaling_initializer())\n",
    "\n",
    "y = tf.placeholder(tf.int32, shape=(None) , name=\"y\")\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits_new))\n",
    "\n",
    "optimzer = tf.train.AdamOptimizer()\n",
    "training_op = optimzer.minimize(loss)\n",
    "\n",
    "acc = tf.reduce_mean(tf.cast(tf.math.in_top_k(logits , tf.cast(y , tf.float32) , 1) , tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = 0\n",
    "with tf.Session() as sess :\n",
    "            sess.run(init)\n",
    "            for epoch in range(n_epoch):\n",
    "                perms = np.random.permutation(num_examples)\n",
    "                Xbatches = np.array_split(Xtrain[perms] , num_examples // batch_size)\n",
    "                ybatches = np.array_split(ytrain[perms] , num_examples // batch_size )\n",
    "                for Xbatch , ybatch in zip(Xbatches , ybatches):\n",
    "                    feed_dict = {X:Xbatch , y:ybatch}\n",
    "                    accu , _ = sess.run([acc , training_op] , feed_dict=feed_dict)\n",
    "                    if accu > before:\n",
    "                        before = accu\n",
    "                        saver.save(sess , \"/tmp/model.ckpt\")\n",
    "                print(accu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
