{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator , ClassifierMixin\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util import deprecation \n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../input/fashion-mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>107</td>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>220</td>\n",
       "      <td>214</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>222</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>134</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>214</td>\n",
       "      <td>163</td>\n",
       "      <td>146</td>\n",
       "      <td>165</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>183</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>102</td>\n",
       "      <td>165</td>\n",
       "      <td>160</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>188</td>\n",
       "      <td>163</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>249</td>\n",
       "      <td>207</td>\n",
       "      <td>197</td>\n",
       "      <td>202</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>116</td>\n",
       "      <td>112</td>\n",
       "      <td>136</td>\n",
       "      <td>147</td>\n",
       "      <td>144</td>\n",
       "      <td>121</td>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2    ...     pixel782  pixel783  pixel784\n",
       "0      2       0       0    ...            0         0         0\n",
       "1      9       0       0    ...            0         0         0\n",
       "2      6       0       0    ...            0         0         0\n",
       "3      0       0       0    ...            0         0         0\n",
       "4      3       0       0    ...            0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = data[\"label\"]\n",
    "Xtrain = data.drop(columns=\"label\" , inplace=False)\n",
    "ytrain = ytrain.values\n",
    "Xtrain = Xtrain.values\n",
    "\n",
    "Xtrain = Xtrain.reshape(-1 , 28 , 28 , 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain , Xval , ytrain , yval = train_test_split(Xtrain , ytrain , test_size=0.004 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"../input/fashion-mnist_test.csv\")\n",
    "\n",
    "ytest = data_test[\"label\"]\n",
    "Xtest = data_test.drop(columns=\"label\" , inplace=False)\n",
    "ytest = ytest.values\n",
    "Xtest = Xtest.values\n",
    "\n",
    "Xtest = Xtest.reshape(-1 , 28 , 28 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(BaseEstimator , ClassifierMixin):\n",
    "    def __init__(self , activation_conv=tf.nn.relu , activation = tf.nn.elu , log_dir = None\n",
    "                , optimizer = tf.train.AdamOptimizer , learning_Rate = 0.001 , batch_norm = False , dropout = None):\n",
    "        self.activation = activation\n",
    "        self.activation_conv = activation_conv\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.learning_Rate = learning_Rate\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self._session = None\n",
    "        self.log_dir = log_dir\n",
    "    \n",
    "    def get_model_params(self):\n",
    "        with self.graph_.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name : self._session.run(gvar) for gvar in gvars}\n",
    "    \n",
    "    def restore_model_params(self , model_params):\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name : self.graph_.get_operation_by_name(gvar_name + \"/Assign\") for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name : assign_op.inputs[1] for gvar_name , assign_op in assign_ops.items()}\n",
    "        self._session.run(list(assign_ops.values()) , feed_dict={init_values[gvar_name] : model_params[gvar_name] for gvar_name in gvar_names})\n",
    "    \n",
    "    def save(self):\n",
    "        saver.save( self._session , \"/tmp/my_model.ckpt\")\n",
    "    \n",
    "    def build_graph(self , graph , device_):\n",
    "        with tf.device(device_) :\n",
    "            with graph.as_default():\n",
    "                X = tf.placeholder(tf.float32 , shape=(None , 28 , 28 , 1) , name=\"X\")\n",
    "                y = tf.placeholder(tf.int32 , shape=(None) , name=\"y\")\n",
    "\n",
    "                if (self.dropout is not None) or (self.batch_norm is True) :\n",
    "                    self.training = tf.placeholder_with_default(False , shape=())\n",
    "                inputs = X\n",
    "\n",
    "                with tf.name_scope(\"CNN\"):\n",
    "                    inputs = tf.layers.conv2d(inputs , filters = 5, activation=self.activation_conv , \n",
    "                                              kernel_size=5 , strides=[1,1] , padding=\"SAME\" , name=\"Conv1\")\n",
    "                    inputs = tf.layers.conv2d(inputs , filters = 20, activation=self.activation_conv , \n",
    "                                              kernel_size=3 , strides=[1,1] , padding=\"SAME\" , name=\"Conv2\")\n",
    "                    inputs = tf.layers.max_pooling2d(inputs , strides=[2,2] , padding=\"VALID\" , pool_size=[2,2] , name=\"Pool1\")\n",
    "                    inputs = tf.layers.conv2d(inputs , filters = 20, activation=self.activation_conv , \n",
    "                                              kernel_size=3 , strides=[1,1] , padding=\"SAME\")\n",
    "                    inputs = tf.nn.local_response_normalization(inputs , depth_radius=2)\n",
    "                    inputs = tf.layers.max_pooling2d(inputs , strides=[2,2] , padding=\"VALID\" , pool_size=[2,2] , name=\"Pool2\")\n",
    "                    inputs = tf.layers.conv2d(inputs , filters = 40, activation=self.activation_conv , \n",
    "                                              kernel_size=5 , strides=[1,1] , padding=\"SAME\")\n",
    "                    #inputs = tf.layers.conv2d(inputs , filters = 100, activation=self.activation_conv , \n",
    "                    #                          kernel_size=3 , strides=[1,1] , padding=\"SAME\")\n",
    "                    #inputs = tf.layers.average_pooling2d(inputs , padding=\"VALID\" , pool_size=7 , strides=1 , name=\"Global_Avg_Pool\")\n",
    "                    inputs = tf.layers.flatten(inputs , name=\"Flatten\")\n",
    "                    if self.dropout is not None :\n",
    "                        inputs = tf.layers.dropout(inputs , self.dropout , training=self.training , name=\"Dropout\")\n",
    "                    inputs = tf.layers.dense(inputs , units=50 , activation=None ,\n",
    "                                             kernel_initializer=tf.variance_scaling_initializer() , name=\"Hidden_Layer\")\n",
    "                    if self.batch_norm:\n",
    "                        inputs = tf.layers.batch_normalization(inputs , momentum=0.9 , training = self.training , name=\"Batch_Norm\")\n",
    "                    inputs = self.activation(inputs)\n",
    "                    logits = tf.layers.dense(inputs , 10 , activation=None , kernel_initializer=tf.variance_scaling_initializer())\n",
    "                with tf.name_scope(\"Cost_Function\"):\n",
    "                    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y , logits=logits)\n",
    "                    loss = tf.reduce_mean(loss , name=\"Loss\")\n",
    "                with tf.name_scope(\"Eval\"):\n",
    "                    self.y_proba = tf.nn.softmax(logits , name = \"Probabilities\")\n",
    "                    accuracy = tf.reduce_mean(tf.cast(tf.math.in_top_k(logits , y , 1),tf.float32) , name=\"Accuracy\")\n",
    "                if self.log_dir is not None :\n",
    "                    with tf.name_scope(\"Logs\"):\n",
    "                        self.loss_sum = tf.summary.scalar(\"Loss\" , loss)\n",
    "                        self.acc_sum = tf.summary.scalar(\"Accuracy\" , accuracy)\n",
    "                        self.file_writer = tf.summary.FileWriter(self.log_dir , tf.get_default_graph())\n",
    "                with tf.name_scope(\"Optimization\"):\n",
    "                    optimizer = self.optimizer(learning_rate = self.learning_Rate)\n",
    "                    #optimizer=tf.train.MomentumOptimizer(use_nesterov=True , momentum=0.9 , learning_rate=self.learning_Rate)\n",
    "                    #optimizer = tf.train.GradientDescentOptimizer(learning_rate = self.learning_Rate)\n",
    "                    training_op = optimizer.minimize(loss)\n",
    "                if self.batch_norm :\n",
    "                    training_op = [ training_op , tf.get_collection(tf.GraphKeys.UPDATE_OPS)]\n",
    "                self.init = tf.global_variables_initializer()\n",
    "                self.saver = tf.train.Saver()\n",
    "            self.X_ = X \n",
    "            self.y_ = y\n",
    "            self.training_op = training_op\n",
    "            self.accuracy = accuracy\n",
    "            self.loss = loss\n",
    "\n",
    "    def fit(self , Xtrain , ytrain ,Xval = None , yval = None ,  batch_size = 50 , n_epoch = 10 , gpu=False):\n",
    "        self.close_session()\n",
    "        \n",
    "        if gpu :\n",
    "            device = \"/gpu:0\"\n",
    "        else :\n",
    "            device = \"/cpu:0\"\n",
    "        \n",
    "        self.graph_ = tf.get_default_graph()\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        num_examples = Xtrain.shape[0]\n",
    "        Xreshaped = Xtrain.reshape( [ num_examples , 28 , 28 , 1 ] )\n",
    "        \n",
    "        max_checks_without_progress = None\n",
    "        checks_without_progress = 0\n",
    "        best_acc = 0\n",
    "        best_params = None\n",
    "        \n",
    "        self.build_graph(graph = self.graph_ ,device_ = device)\n",
    "        config = tf.ConfigProto(allow_soft_placement = True)\n",
    "        self._session = tf.Session(graph=self.graph_ , config = config)\n",
    "        \n",
    "        if Xval is not None and yval is not None:\n",
    "            feed_dict_val = {self.X_ : Xval , self.y_:yval}\n",
    "        else :\n",
    "            feed_dict_val = None\n",
    "        if n_epoch == 'optimum' :\n",
    "            n_epoch = 200\n",
    "            max_checks_without_progress = 4500\n",
    "        \n",
    "        with self._session.as_default() as sess :\n",
    "            sess.run(self.init)\n",
    "            for epoch in range(n_epoch):\n",
    "                perms = np.random.permutation(num_examples)\n",
    "                Xbatches = np.array_split(Xreshaped[perms] , num_examples // batch_size)\n",
    "                ybatches = np.array_split(ytrain[perms] , num_examples // batch_size )\n",
    "                for Xbatch , ybatch in zip(Xbatches , ybatches):\n",
    "                    feed_dict = {self.X_:Xbatch , self.y_:ybatch}\n",
    "                    if self.batch_norm or self.dropout :\n",
    "                        feed_dict[self.training] = True\n",
    "                    sess.run(self.training_op , feed_dict=feed_dict)\n",
    "                    \n",
    "                    if feed_dict_val :\n",
    "                        acc = self.accuracy.eval(feed_dict = feed_dict_val)\n",
    "                        if self.log_dir is not None :\n",
    "                            Ls = self.loss_sum.eval(feed_dict = feed_dict_val)\n",
    "                            As = self.acc_sum.eval(feed_dict = feed_dict_val)\n",
    "                            for s in Ls , As :\n",
    "                                self.file_writer.add_summary(s) \n",
    "                    else :\n",
    "                        if self.batch_norm or self.dropout :\n",
    "                            feed_dict[self.training] = False\n",
    "                        acc = self.accuracy.eval(feed_dict)\n",
    "                        if self.log_dir is not None :\n",
    "                            Ls = self.loss_sum.eval(feed_dict = feed_dict)\n",
    "                            As = self.acc_sum.eval(feed_dict = feed_dict)\n",
    "                            for s in Ls , As :\n",
    "                                self.file_writer.add_summary(s , step + epoch * (num_examples // batch_size))\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_params = self.get_model_params()\n",
    "                    else :\n",
    "                        checks_without_progress = checks_without_progress + 1\n",
    "                    if max_checks_without_progress is not None :    \n",
    "                        if checks_without_progress > max_checks_without_progress :\n",
    "                            break\n",
    "                else :\n",
    "                    print(\"Epoch {} Accuracy : {} | Best : {}\".format(epoch + 1 , acc , best_acc))\n",
    "                    continue\n",
    "                print(\"Epoch {} Accuracy : {} | Best : {} [Incomplete Epoch]\".format(epoch + 1 , acc , best_acc))\n",
    "                break\n",
    "            self.restore_model_params(best_params)\n",
    "            return\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "    def predict(self , X):\n",
    "        return np.argmax(self.predict_proba(X) , axis=1)\n",
    "    def predict_proba(self , X):\n",
    "        if self._session :\n",
    "            return self._session.run(self.y_proba , feed_dict = {self.X_:X})\n",
    "        else:\n",
    "            raise NotFittedError(\"Not Fitted Yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CNNClassifier(dropout=0.4 , batch_norm=True , learning_Rate=0.0008  , log_dir=\"tf_logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Accuracy : 0.925000011920929 | Best : 0.9375\n",
      "Epoch 2 Accuracy : 0.925000011920929 | Best : 0.9458333253860474\n",
      "Epoch 3 Accuracy : 0.9458333253860474 | Best : 0.9541666507720947\n",
      "Epoch 4 Accuracy : 0.9333333373069763 | Best : 0.9666666388511658\n",
      "Epoch 5 Accuracy : 0.9125000238418579 | Best : 0.9666666388511658\n",
      "Epoch 6 Accuracy : 0.9333333373069763 | Best : 0.9666666388511658\n",
      "Epoch 7 Accuracy : 0.9375 | Best : 0.9666666388511658\n",
      "Epoch 8 Accuracy : 0.9333333373069763 | Best : 0.9666666388511658\n",
      "Epoch 9 Accuracy : 0.925000011920929 | Best : 0.9666666388511658\n",
      "Epoch 10 Accuracy : 0.9375 | Best : 0.9666666388511658\n",
      "Epoch 11 Accuracy : 0.9333333373069763 | Best : 0.9666666388511658\n",
      "Epoch 12 Accuracy : 0.949999988079071 | Best : 0.9666666388511658\n",
      "Epoch 13 Accuracy : 0.9416666626930237 | Best : 0.9666666388511658\n",
      "Epoch 14 Accuracy : 0.9458333253860474 | Best : 0.9666666388511658\n",
      "Epoch 15 Accuracy : 0.9375 | Best : 0.9666666388511658\n",
      "Epoch 16 Accuracy : 0.9458333253860474 | Best : 0.9666666388511658\n",
      "Epoch 17 Accuracy : 0.9458333253860474 | Best : 0.9666666388511658\n",
      "Epoch 18 Accuracy : 0.9458333253860474 | Best : 0.9666666388511658\n",
      "Epoch 19 Accuracy : 0.9458333253860474 | Best : 0.9708333611488342\n",
      "Epoch 20 Accuracy : 0.9375 | Best : 0.9708333611488342\n"
     ]
    }
   ],
   "source": [
    "clf.fit(Xtrain , ytrain, Xval , yval , 50 , 20  , gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker(img):\n",
    "    plt.imshow(img.reshape([28 , 28]))\n",
    "    plt.show()\n",
    "    print(clf.predict(img.reshape([-1 , 28 , 28 , 1])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "checker(Xtrain[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.9247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(Xtest)\n",
    "test_accuracy = accuracy_score(ytest , y_pred)\n",
    "\n",
    "print(\"Test Accuracy : {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- JUPYTER_TENSORBOARD_TEST_MARKER -->\n",
       "<script>\n",
       "    const req = {\n",
       "        method: 'POST',\n",
       "        contentType: 'application/json',\n",
       "        body: JSON.stringify({ 'logdir': 'tf_logs' }),\n",
       "        headers: { 'Content-Type': 'application/json' }\n",
       "    };\n",
       "\n",
       "    const baseUrl = Jupyter.notebook.base_url;\n",
       "\n",
       "    fetch(baseUrl + 'api/tensorboard', req)\n",
       "        .then(res => res.json())\n",
       "        .then(res => {\n",
       "            const iframe = document.getElementById('tensorboard-ef8cff3a-dcae-4aa9-be10-c9027e710a2b');\n",
       "            iframe.src = baseUrl + 'tensorboard/' + res.name;\n",
       "            iframe.style.display = 'block';\n",
       "        });\n",
       "</script>\n",
       "\n",
       "<iframe\n",
       "    id=\"tensorboard-ef8cff3a-dcae-4aa9-be10-c9027e710a2b\"\n",
       "    style=\"width: 100%; height: 620px; display: none;\"\n",
       "    frameBorder=\"0\">\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir tf_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r tf_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Saved/my_model.ckpt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.saver.save(clf._session , \"/Saved/my_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
